{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_hy9iCXlaax"
   },
   "source": [
    "# CNN Fine Tuning for Cats-Dogs Classification\n",
    "## CIML Summer Institute, UC San Diego\n",
    "Fine-tune VGG16 top layer (Conv block 5) and fully connected layers to classify cats vs. dogs. \n",
    "Adapted from tensorflow tutorials (https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb)\n",
    "\n",
    "------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8NmDHijos0sW"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gjRHT_7ds0sX",
    "outputId": "67d5215b-c5a4-47fa-ee1e-4f13177ec0c7"
   },
   "outputs": [],
   "source": [
    "print (tf.__version__)\n",
    "!python --version\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5OAYvK0s0sX"
   },
   "outputs": [],
   "source": [
    "# Set logging level\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qd4JjV5Cs0sX"
   },
   "outputs": [],
   "source": [
    "# Set random generator seed\n",
    "seed = 1234\n",
    "\n",
    "# Disable hash randomization by specifying the value 0.\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# Set numpy random generator\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set python built-in random generator\n",
    "random.seed(seed)\n",
    "\n",
    "# Set tf global random seed\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Set tensorflow graph-level random seed\n",
    "tf.compat.v1.random.set_random_seed(seed)\n",
    "\n",
    "# Potential randomness from CUDNN\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_DETERMINISTIC']= '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLToN9Hxs0sY"
   },
   "source": [
    "### Set image dimensions, location of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dimensions\n",
    "img_width, img_height = 150, 150\n",
    "IMG_SIZE = (img_width,img_height)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "\n",
    "# Location of images\n",
    "HOME = os.path.expanduser('~') \n",
    "data_path = HOME + '/data/catsVsDogs'\n",
    "\n",
    "train_data_dir = data_path + '/train'\n",
    "validation_data_dir = data_path + '/val'\n",
    "test_data_dir = data_path + '/test'\n",
    "\n",
    "print ('Train path:' + train_data_dir)\n",
    "print ('Validation:' + validation_data_dir)\n",
    "print ('Test path:' + test_data_dir)\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data setup\n",
    "train_datagen = ImageDataGenerator(rescale = 1. / 255, shear_range = 0.2,\n",
    "                                   zoom_range = 0.2, horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1. / 255)\n",
    "validation_datagen = ImageDataGenerator(rescale = 1. / 255)\n",
    "\n",
    "# Set up generator to read images found in subfolders of training data directory,\n",
    "# and indefinitely generate batches of image data (scaled).  This is for training data.\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=IMG_SIZE,\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    class_mode='binary', \n",
    "                                                    shuffle = True,\n",
    "                                                    seed = seed)           \n",
    "\n",
    "# Set up generator to generate batched of validation data for model\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_data_dir,\n",
    "                                                              target_size=IMG_SIZE,\n",
    "                                                              batch_size = BATCH_SIZE,\n",
    "                                                              class_mode='binary',\n",
    "                                                              shuffle = False, \n",
    "                                                              seed = seed)\n",
    "# Set up generator to generate batched of test data for model\n",
    "test_generator = test_datagen.flow_from_directory(test_data_dir,\n",
    "                                                  target_size=IMG_SIZE,\n",
    "                                                  batch_size = BATCH_SIZE,\n",
    "                                                  class_mode='binary',\n",
    "                                                  shuffle = False,\n",
    "                                                  seed = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model from feature extraction\n",
    "Load model saved from feature extraction.\n",
    "\n",
    "Weights in last convoluational layer and top model will be adjusted.  All other weights are frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('weights_from_feature_extract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all weights of VGG16 model except for conv block5\n",
    "for layers in model.layers[0].layers[:15]:\n",
    "    layers.trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "# Compile model with Adam optimizer with very slow learning rate,\n",
    "# Binary Cross-Entropy loss function and Accuracy metric\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.000005),\n",
    "              loss= losses.BinaryCrossentropy(),metrics=['accuracy'])\n",
    "\n",
    "# Early Stopping to avoid overfitting and ModelCheckpoint to save the best model\n",
    "checkpoint_path = 'tmp/checkpoint'\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3, min_delta=0.001,\n",
    "                           mode='min'),\n",
    "             ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss',\n",
    "                             mode = 'min', save_best_only = True, \n",
    "                             save_weights_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_history = model.fit(train_generator,epochs=EPOCHS, \n",
    "                          validation_data=validation_generator, \n",
    "                          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model that was saved using ModelCheckpoint\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train and validation history\n",
    "fig, axs = plt.subplots(1,2, figsize= (20,5))\n",
    "axs[0].plot(train_history.history['loss'])\n",
    "axs[0].plot(train_history.history['val_loss'])\n",
    "axs[0].set_title(\"Train, Val loss history\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "axs[0].legend([\"Train Loss\",\"Val Loss\"])\n",
    "\n",
    "axs[1].plot(train_history.history['accuracy'])\n",
    "axs[1].plot(train_history.history['val_accuracy'])\n",
    "axs[1].set_title(\"Train, Val Accuracy history\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "axs[1].legend([\"Train Accuracy\",\"Val Accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, train_accuracy = model.evaluate(train_generator)\n",
    "print(\"Train data accuracy:\", train_accuracy)\n",
    "\n",
    "_, test_accuracy = model.evaluate(test_generator)\n",
    "print(\"Test data accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted value and the ground truth value of test data\n",
    "pred = (model.predict(test_generator) > 0.5).astype(\"int32\")\n",
    "true = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_true= true, y_pred = pred, target_names=['cats', 'dogs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform inference on test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_loader(img_file):\n",
    "    \"\"\"load individual images\"\"\"\n",
    "    img = load_img(img_file, target_size = (img_width, img_height))\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show()\n",
    "    img = img_to_array(img) / 255\n",
    "    img = np.expand_dims(img, axis = 0) #model input is (1,150,150,3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = data_path + '/test/cats/cat.1070.jpg'\n",
    "img = image_loader(test_image)\n",
    "img_y_pred = model.predict(img) \n",
    "print(img_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = data_path + '/test/dogs/dog.1233.jpg'\n",
    "img = image_loader(test_image)\n",
    "img_y_pred = model.predict(img) \n",
    "print(img_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = data_path + '/test/cats/cat.1195.jpg'\n",
    "img = image_loader(test_image)\n",
    "img_y_pred = model.predict(img) \n",
    "print(img_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = data_path + '/test/cats/cat.1011.jpg'\n",
    "img = image_loader(test_image)\n",
    "img_y_pred = model.predict(img) \n",
    "print(img_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = data_path + '/test/dogs/dog.1308.jpg'\n",
    "img = image_loader(test_image)\n",
    "img_y_pred = model.predict(img) \n",
    "print(img_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = data_path + '/test/dogs/dog.1342.jpg'\n",
    "img = image_loader(test_image)\n",
    "img_y_pred = model.predict(img) \n",
    "print(img_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "features_final_soln_tfl.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
